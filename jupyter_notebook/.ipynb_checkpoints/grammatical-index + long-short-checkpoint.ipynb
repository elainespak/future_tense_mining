{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from contextlib import redirect_stderr\n",
    "from nltk import FreqDist\n",
    "from nltk import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import re\n",
    "df_us_10k = pd.read_csv('D:\\\\data\\\\finance\\\\financial_statements\\\\us\\\\SEC-preprocessed-download\\\\10k_2009_2019.csv', encoding='utf-8')\n",
    "df_kospi_10k_1115 = pd.read_csv('D:\\\\data\\\\finance\\\\financial_statements\\\\kr\\\\kospi200_2011_2015_translated.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def will_occurences(string):\n",
    "    return len(re.findall('(?!A\\s*|The\\s*)(will)', string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf with skelarn - \n",
    "vectorizer = TfidfVectorizer(vocabulary={'will':0, 'shall':1})\n",
    "X = vectorizer.fit_transform(df_i_want['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_tf = pd.DataFrame(columns=('adsh', 'gvkey', 'cik', 'filed'))\n",
    "df_us_tf[['adsh', 'gvkey', 'cik', 'filed']] = df_us_10k[['adsh', 'gvkey', 'cik', 'filed']].dropna()\n",
    "df_us_tf['will'] = df_us_10k['text'].dropna().apply(will_occurences)\n",
    "df_us_tf['shall'] = df_us_10k['text'].dropna().str.count('shall')\n",
    "df_us_tf['going_to'] = df_us_10k['text'].dropna().str.count('going to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_tf['expect_to'] = df_us_10k['text'].dropna().str.count('expect to')\n",
    "df_us_tf['expected_to'] = df_us_10k['text'].dropna().str.count('expected to')\n",
    "df_us_tf['expecting_to'] = df_us_10k['text'].dropna().str.count('expecting to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "will            18.653786\n",
       "shall            0.150051\n",
       "going_to         0.004285\n",
       "expect_to        0.594213\n",
       "expecting_to     0.002124\n",
       "expected_to      3.090782\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_tf[['will', 'shall', 'going_to', 'expect_to', 'expecting_to', 'expected_to']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adsh</th>\n",
       "      <th>cik</th>\n",
       "      <th>filed</th>\n",
       "      <th>will</th>\n",
       "      <th>shall</th>\n",
       "      <th>going_to</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       adsh  cik  filed  will  shall  going_to\n",
       "filed                                         \n",
       "2009     25   25     25    25     25        25\n",
       "2010     51   51     51    51     51        51\n",
       "2011     38   38     38    38     38        38\n",
       "2012     47   47     47    47     47        47\n",
       "2013     59   59     59    59     59        59\n",
       "2014     36   36     36    36     36        36\n",
       "2015     18   18     18    18     18        18\n",
       "2016     27   27     27    27     27        27\n",
       "2017     28   28     28    28     28        28\n",
       "2018     14   14     14    14     14        14\n",
       "2019     12   12     12    12     12        12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_tf.filed = pd.to_datetime(df_us_tf.filed, format='%Y%m%d')\n",
    "df_us_tf[df_us_tf.will==0].groupby(df_us_tf.filed.dt.year).count()\n",
    "#will이 1개도 등장하지 않는 애들이 약 30~40개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KOSPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kospi_10k_1115[df_kospi_10k_1115.Translated.isnull()]\n",
    "df_kr_tf = pd.DataFrame(columns=['file'])\n",
    "df_kr_tf[['file']] = df_kospi_10k_1115[['File']].dropna()\n",
    "df_kr_tf['will'] = df_kospi_10k_1115['Translated'].dropna().apply(will_occurences)\n",
    "df_kr_tf['shall'] = df_kospi_10k_1115['Translated'].dropna().str.count('shall')\n",
    "df_kr_tf['going_to'] = df_kospi_10k_1115['Translated'].dropna().str.count('going to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "will        7.084703\n",
       "shall       0.119014\n",
       "going_to    0.021444\n",
       "dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kr_tf[['will', 'shall', 'going_to']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylim2357\\anaconda3\\envs\\future-tense-mining\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "price_df = pd.read_csv('D:\\\\data\\\\finance\\\\price\\\\prices_08_19.csv')\n",
    "stocks_of_interest = df_us_tf.gvkey.unique()\n",
    "price_df['datadate'] = pd.to_datetime(price_df['datadate'], format='%Y%m%d')\n",
    "price_df = price_df[price_df.gvkey.isin(stocks_of_interest)]\n",
    "price_df['adj_closing_price'] = price_df['prccd'] / price_df['ajexdi']\n",
    "price_df = price_df[['gvkey', 'datadate', 'tic', 'adj_closing_price']]\n",
    "price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_json('C:\\\\Users\\\\sylim2357\\\\Documents\\\\SNU\\\\Projects\\\\FVID\\\\data\\\\KRX\\\\kospi200_configs\\\\kospi_submission_date.json')\n",
    "df_sentiment = pd.read_csv('C:\\\\Users\\\\sylim2357\\\\Documents\\\\SNU\\\\Projects\\\\FVID\\\\data\\\\KRX\\\\kospi_sentiment\\\\kospi_sentiment_2011_2019.csv')\n",
    "market_days = pd.to_datetime(pd.read_csv('C:\\\\Users\\\\sylim2357\\\\Documents\\\\SNU\\\\Projects\\\\FVID\\\\data\\\\KRX\\\\date_normal.csv')['Date'])\n",
    "\n",
    "submission_df = submission_df[~submission_df['file_name'].str.contains(']')]\n",
    "submission_df['file_name'] = submission_df['file_name'].str.split('.pdf', expand=True).iloc[:,0]\n",
    "submission_df['company_code'] = submission_df['file_name'].str.split('_',expand=True).iloc[:,0]\n",
    "submission_df['submission_date'] = pd.to_datetime(submission_df['submission_date'], format='%Y%m%d')\n",
    "#constructing rebalancing dates\n",
    "fidq_dates_suffix_list = ['-01-20 00:00:00','-04-20 00:00:00','-07-20 00:00:00','-10-20 00:00:00']\n",
    "years = list(set([x.year for x in submission_df['submission_date']]))\n",
    "years.sort()\n",
    "fidq_dates_list = [pd.Timestamp(str(years[0]-1))] + [pd.Timestamp(str(year)+suffix) for year in years for suffix in fidq_dates_suffix_list] + [pd.Timestamp(str(years[-1]+1)+fidq_dates_suffix_list[0])]\n",
    "submission_df['rebalance_date'] = pd.cut(submission_df['submission_date'], fidq_dates_list, labels = fidq_dates_list[1:])\n",
    "#quantiling the sentiments per rebalance date\n",
    "sentiment_submission_df = submission_df.merge(df_sentiment, left_on='file_name', right_on='File').drop('File', axis=1)\n",
    "sentiment_submission_df['polarity_quantile'] = sentiment_submission_df.groupby('rebalance_date', level=0).apply(pd.DataFrame.sort_values, 'Polarity', ascending=False)['Polarity'].transform(lambda x: pd.qcut(x, 4, labels=range(1,5)))\n",
    "#filtering only top and bottom quantiles\n",
    "sentiment_submission_top_bottom_df = sentiment_submission_df[sentiment_submission_df.polarity_quantile.isin([1,4])]\n",
    "sentiment_submission_top_bottom_df['rebalance_date'] = pd.to_datetime(sentiment_submission_top_bottom_df['rebalance_date'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:future-tense-mining]",
   "language": "python",
   "name": "conda-env-future-tense-mining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
