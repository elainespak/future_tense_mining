{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from contextlib import redirect_stderr\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import time\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-34e744907cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://www.sec.gov/Archives/edgar/data/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cik'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adsh'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adsh'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adsh'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "path = 'D:\\\\data\\\\finance\\\\financial_statements\\\\us\\\\EDGAR-raw'\n",
    "# df = pd.read_csv('D:\\\\data\\\\finance\\\\financial_statements\\\\us\\\\10k_2009_2019.csv', encoding='utf-8')\n",
    "for idx, row in df.drop_duplicates().drop(['text', 'quarter'], axis=1).iterrows():\n",
    "    url = 'https://www.sec.gov/Archives/edgar/data/' + str(row['cik']) + '/' + ''.join(row['adsh'].split('-')) + '/' + row['adsh'] + '.txt'\n",
    "    urllib.request.urlretrieve(url,path + '\\\\' + row['adsh'] + '.txt')\n",
    "    time.sleep(np.random.randint(1,400)/200)\n",
    "    if idx % 100 == 0:\n",
    "        print(row.filed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adsh</th>\n",
       "      <th>cik</th>\n",
       "      <th>gvkey</th>\n",
       "      <th>name</th>\n",
       "      <th>form</th>\n",
       "      <th>quarter</th>\n",
       "      <th>filed</th>\n",
       "      <th>text</th>\n",
       "      <th>co_conm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000038074-09-000029</td>\n",
       "      <td>38074</td>\n",
       "      <td>4843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-05-29</td>\n",
       "      <td>10. Accrued expenses (In thousands) : Accrued ...</td>\n",
       "      <td>FOREST LABORATORIES  -CL A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000277948-09-000066</td>\n",
       "      <td>277948</td>\n",
       "      <td>2574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-04-15</td>\n",
       "      <td>CSX CORPORATION. NOTE 9. Income Taxes As of Ma...</td>\n",
       "      <td>CSX CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000796343-09-000026</td>\n",
       "      <td>796343</td>\n",
       "      <td>12540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-06-26</td>\n",
       "      <td>NOTE 5. ACCRUED EXPENSES Accrued expenses as o...</td>\n",
       "      <td>ADOBE INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000831259-09-000047</td>\n",
       "      <td>831259</td>\n",
       "      <td>14590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-05-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FREEPORT-MCMORAN INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000891618-09-000150</td>\n",
       "      <td>1164727</td>\n",
       "      <td>7881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009-04-30</td>\n",
       "      <td>NOTE 23 RECLAMATION AND REMEDIATION LIABILITIE...</td>\n",
       "      <td>NEWMONT CORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26415</th>\n",
       "      <td>0001751788-19-000031</td>\n",
       "      <td>1751788</td>\n",
       "      <td>34443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>CONSOLIDATED FINANCIAL STATEMENTS Merger and S...</td>\n",
       "      <td>DOW INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26416</th>\n",
       "      <td>0001752836-19-000061</td>\n",
       "      <td>1752836</td>\n",
       "      <td>34765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>Supplemental cash flow information related to ...</td>\n",
       "      <td>COVETRUS INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26417</th>\n",
       "      <td>0001755672-19-000028</td>\n",
       "      <td>1755672</td>\n",
       "      <td>35168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>BACKGROUND AND BASIS OF PRESENTATION Corteva, ...</td>\n",
       "      <td>CORTEVA INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26418</th>\n",
       "      <td>0001760965-19-000023</td>\n",
       "      <td>1760965</td>\n",
       "      <td>35035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>BASIS OF PRESENTATION Description of Business ...</td>\n",
       "      <td>KONTOOR BRANDS INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26419</th>\n",
       "      <td>0001770450-19-000014</td>\n",
       "      <td>1770450</td>\n",
       "      <td>11636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-06</td>\n",
       "      <td>Basis of Presentation References to Xerox Hold...</td>\n",
       "      <td>XEROX HOLDINGS CORP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26420 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       adsh      cik  gvkey  name  form  quarter      filed  \\\n",
       "0      0000038074-09-000029    38074   4843   NaN  10-K      NaN 2009-05-29   \n",
       "1      0000277948-09-000066   277948   2574   NaN  10-Q      NaN 2009-04-15   \n",
       "2      0000796343-09-000026   796343  12540   NaN  10-Q      NaN 2009-06-26   \n",
       "3      0000831259-09-000047   831259  14590   NaN  10-Q      NaN 2009-05-11   \n",
       "4      0000891618-09-000150  1164727   7881   NaN  10-Q      NaN 2009-04-30   \n",
       "...                     ...      ...    ...   ...   ...      ...        ...   \n",
       "26415  0001751788-19-000031  1751788  34443   NaN  10-Q      NaN 2019-10-25   \n",
       "26416  0001752836-19-000061  1752836  34765   NaN  10-Q      NaN 2019-11-12   \n",
       "26417  0001755672-19-000028  1755672  35168   NaN  10-Q      NaN 2019-10-31   \n",
       "26418  0001760965-19-000023  1760965  35035   NaN  10-Q      NaN 2019-11-12   \n",
       "26419  0001770450-19-000014  1770450  11636   NaN  10-Q      NaN 2019-11-06   \n",
       "\n",
       "                                                    text  \\\n",
       "0      10. Accrued expenses (In thousands) : Accrued ...   \n",
       "1      CSX CORPORATION. NOTE 9. Income Taxes As of Ma...   \n",
       "2      NOTE 5. ACCRUED EXPENSES Accrued expenses as o...   \n",
       "3                                                    NaN   \n",
       "4      NOTE 23 RECLAMATION AND REMEDIATION LIABILITIE...   \n",
       "...                                                  ...   \n",
       "26415  CONSOLIDATED FINANCIAL STATEMENTS Merger and S...   \n",
       "26416  Supplemental cash flow information related to ...   \n",
       "26417  BACKGROUND AND BASIS OF PRESENTATION Corteva, ...   \n",
       "26418  BASIS OF PRESENTATION Description of Business ...   \n",
       "26419  Basis of Presentation References to Xerox Hold...   \n",
       "\n",
       "                          co_conm  \n",
       "0      FOREST LABORATORIES  -CL A  \n",
       "1                        CSX CORP  \n",
       "2                       ADOBE INC  \n",
       "3            FREEPORT-MCMORAN INC  \n",
       "4                    NEWMONT CORP  \n",
       "...                           ...  \n",
       "26415                     DOW INC  \n",
       "26416                COVETRUS INC  \n",
       "26417                 CORTEVA INC  \n",
       "26418          KONTOOR BRANDS INC  \n",
       "26419         XEROX HOLDINGS CORP  \n",
       "\n",
       "[26420 rows x 9 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'D:\\\\data\\\\finance'\n",
    "\n",
    "df_index = pd.read_csv(base_dir + '\\\\index_constituents.csv')\n",
    "df_index_sp = df_index[df_index.conm == 'S&P 500 Comp-Ltd']\n",
    "# df_sub = pd.read_csv(base_dir + '\\\\financial_statements\\\\us\\\\2019q4_notes\\\\sub.tsv', delimiter='\\t')\n",
    "# df_txt = pd.read_csv(base_dir + '\\\\financial_statements\\\\us\\\\2019q4_notes\\\\txt.tsv', delimiter='\\t')\n",
    "FORM_OF_INTEREST = ['10-Q', '10-K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path):\n",
    "    with open(file_path, encoding = \"ISO-8859-1\") as f:\n",
    "        columns = []\n",
    "        lines_dicts = []\n",
    "        for idx, line in enumerate(f):\n",
    "            split = line.split('\\n')[0].split('\\t')\n",
    "            if idx == 0:\n",
    "                columns += split\n",
    "            elif len(split) == 20:\n",
    "                lines_dicts += [dict(zip(columns, split))]\n",
    "            else:\n",
    "                lines_dicts += [dict(zip(columns, split[:19] + [' '.join(split[19:])]))]\n",
    "                \n",
    "    return pd.DataFrame(lines_dicts)[['adsh', 'tag', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\data\\finance\\financial_statements\\us\\2009q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2009q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2009q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2009q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q4_notes\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylim2357\\anaconda3\\envs\\future-tense-mining\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3062: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\data\\finance\\financial_statements\\us\\2012q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2012q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2012q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2012q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q4_notes\\\n"
     ]
    }
   ],
   "source": [
    "df_i_want = pd.DataFrame(columns=['adsh', 'cik', 'gvkey', 'name', 'form', 'quarter', 'filed', 'text'])\n",
    "df_i_want = df_i_want.set_index('adsh')\n",
    "err = []\n",
    "stderr_out = []\n",
    "for yr in range(11):\n",
    "    for q in range(4):\n",
    "        file_dir = base_dir + '\\\\financial_statements\\\\us\\\\' + str(2009+yr) + 'q' + str(q+1) + '_notes\\\\'\n",
    "        \n",
    "        print(file_dir)\n",
    "        df_sub = pd.read_csv(file_dir + 'sub.tsv', delimiter='\\t', encoding = \"ISO-8859-1\")\n",
    "        try:\n",
    "            df_txt = pd.read_csv(file_dir + 'txt.tsv', delimiter='\\t', encoding = \"ISO-8859-1\")[['adsh', 'tag', 'value']]\n",
    "        except:\n",
    "            df_txt = read_csv(file_dir + 'txt.tsv')[['adsh', 'tag', 'value']]\n",
    "            \n",
    "        df_sub = pd.merge(df_sub[df_sub.form.isin(FORM_OF_INTEREST)][['adsh', 'cik', 'filed', 'form']], \\\n",
    "                          df_index_sp[['gvkey', 'co_cik', 'co_conm', 'from', 'thru']], left_on='cik', right_on='co_cik', how='inner').drop('co_cik', axis=1)\n",
    "        \n",
    "        df_txt = df_txt[['adsh', 'tag', 'value']]\n",
    "        df_txt = df_txt[(df_txt.tag.str.contains('TextBlock')) & (~df_txt.value.isnull())]\n",
    "        \n",
    "        df = pd.merge(df_txt, df_sub['adsh'], on='adsh')\n",
    "        df_sub = df_sub[['adsh', 'cik', 'gvkey', 'co_conm', 'form', 'filed']].set_index('adsh')\n",
    "        df_i_want = df_i_want.append(df_sub)\n",
    "        for adsh in df_sub.index:\n",
    "            try:\n",
    "                df_i_want.loc[adsh, 'text'] = '. '.join(df[(df.adsh == adsh)].value)\n",
    "            except:\n",
    "                print(adsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_want.to_csv('10k_2009_2019.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:future-tense-mining]",
   "language": "python",
   "name": "conda-env-future-tense-mining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
