{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from contextlib import redirect_stderr\n",
    "from nltk import FreqDist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib\n",
    "import time\n",
    "import glob\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'D:\\\\data\\\\finance'\n",
    "\n",
    "df_index = pd.read_csv(base_dir + '\\\\index_constituents.csv')\n",
    "df_index_sp = df_index[df_index.conm == 'S&P 500 Comp-Ltd']\n",
    "# df_sub = pd.read_csv(base_dir + '\\\\financial_statements\\\\us\\\\2019q4_notes\\\\sub.tsv', delimiter='\\t')\n",
    "# df_txt = pd.read_csv(base_dir + '\\\\financial_statements\\\\us\\\\2019q4_notes\\\\txt.tsv', delimiter='\\t')\n",
    "FORM_OF_INTEREST = ['10-Q', '10-K']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-05 00:00:00\n",
      "2019-12-05 00:00:00\n",
      "2019-11-07 00:00:00\n",
      "2019-11-08 00:00:00\n",
      "2019-10-28 00:00:00\n",
      "2019-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "path = 'D:\\\\data\\\\finance\\\\financial_statements\\\\us\\\\EDGAR-raw'\n",
    "df = pd.read_csv('D:\\\\data\\\\finance\\\\financial_statements\\\\us\\\\10k_2009_2019.csv', encoding='utf-8')\n",
    "for idx, row in df.drop_duplicates().drop(['text', 'quarter'], axis=1).iterrows():\n",
    "    url = 'https://www.sec.gov/Archives/edgar/data/' + str(row['cik']) + '/' + ''.join(row['adsh'].split('-')) + '/' + row['adsh'] + '.txt'\n",
    "    urllib.request.urlretrieve(url,path + '\\\\' + row['adsh'] + '.txt')\n",
    "    time.sleep(np.random.randint(100,400)/200)\n",
    "    if idx % 100 == 0:\n",
    "        print(row.filed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path):\n",
    "    with open(file_path, encoding = \"ISO-8859-1\") as f:\n",
    "        columns = []\n",
    "        lines_dicts = []\n",
    "        for idx, line in enumerate(f):\n",
    "            split = line.split('\\n')[0].split('\\t')\n",
    "            if idx == 0:\n",
    "                columns += split\n",
    "            elif len(split) == 20:\n",
    "                lines_dicts += [dict(zip(columns, split))]\n",
    "            else:\n",
    "                lines_dicts += [dict(zip(columns, split[:19] + [' '.join(split[19:])]))]\n",
    "                \n",
    "    return pd.DataFrame(lines_dicts)[['adsh', 'tag', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\data\\finance\\financial_statements\\us\\2009q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2009q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2009q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2009q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2010q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2011q4_notes\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sylim2357\\anaconda3\\envs\\future-tense-mining\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3062: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\data\\finance\\financial_statements\\us\\2012q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2012q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2012q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2012q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2013q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2014q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2015q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2016q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2017q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2018q4_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q1_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q2_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q3_notes\\\n",
      "D:\\data\\finance\\financial_statements\\us\\2019q4_notes\\\n"
     ]
    }
   ],
   "source": [
    "df_i_want = pd.DataFrame(columns=['adsh', 'cik', 'gvkey', 'name', 'form', 'quarter', 'filed', 'text'])\n",
    "df_i_want = df_i_want.set_index('adsh')\n",
    "err = []\n",
    "stderr_out = []\n",
    "for yr in range(11):\n",
    "    for q in range(4):\n",
    "        file_dir = base_dir + '\\\\financial_statements\\\\us\\\\' + str(2009+yr) + 'q' + str(q+1) + '_notes\\\\'\n",
    "        \n",
    "        print(file_dir)\n",
    "        df_sub = pd.read_csv(file_dir + 'sub.tsv', delimiter='\\t', encoding = \"ISO-8859-1\")\n",
    "        try:\n",
    "            df_txt = pd.read_csv(file_dir + 'txt.tsv', delimiter='\\t', encoding = \"ISO-8859-1\")[['adsh', 'tag', 'value']]\n",
    "        except:\n",
    "            df_txt = read_csv(file_dir + 'txt.tsv')[['adsh', 'tag', 'value']]\n",
    "            \n",
    "        df_sub = pd.merge(df_sub[df_sub.form.isin(FORM_OF_INTEREST)][['adsh', 'cik', 'filed', 'form']], \\\n",
    "                          df_index_sp[['gvkey', 'co_cik', 'co_conm', 'from', 'thru']], left_on='cik', right_on='co_cik', how='inner').drop('co_cik', axis=1)\n",
    "        \n",
    "        df_txt = df_txt[['adsh', 'tag', 'value']]\n",
    "        df_txt = df_txt[(df_txt.tag.str.contains('TextBlock')) & (~df_txt.value.isnull())]\n",
    "        \n",
    "        df = pd.merge(df_txt, df_sub['adsh'], on='adsh')\n",
    "        df_sub = df_sub[['adsh', 'cik', 'gvkey', 'co_conm', 'form', 'filed']].set_index('adsh')\n",
    "        df_i_want = df_i_want.append(df_sub)\n",
    "        for adsh in df_sub.index:\n",
    "            try:\n",
    "                df_i_want.loc[adsh, 'text'] = '. '.join(df[(df.adsh == adsh)].value)\n",
    "            except:\n",
    "                print(adsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i_want.to_csv('10k_2009_2019.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:future-tense-mining]",
   "language": "python",
   "name": "conda-env-future-tense-mining-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
